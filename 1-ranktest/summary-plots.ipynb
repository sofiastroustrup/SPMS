{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.backends.backend_pdf as backend_pdf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from numpy import genfromtxt\n",
    "from ete3 import Tree\n",
    "import seaborn as sns\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnodes = 9\n",
    "tree = Tree('../data/chazot_subtree.nw') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leafidx = []\n",
    "inneridx = []\n",
    "i = 0\n",
    "for node in tree.traverse('levelorder'):\n",
    "    if node.is_leaf():\n",
    "        print(node.name)\n",
    "        leafidx.append(i)\n",
    "    else:\n",
    "        inneridx.append(i)\n",
    "    i+=1\n",
    "print(leafidx)\n",
    "print(inneridx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = re.compile('^_')\n",
    "_folder = '../_BM14/runs' # change this to the folder where the runs from ranktest are \n",
    "bfolder = os.listdir(_folder)\n",
    "bfolder_ignore = ['.DS_Store', 'README.txt', '_','figures', 'other', 'rhat-paths.pdf', 'mse_paths.pdf', 'rhat-pars.pdf', 'bias_paths.pdf','bias_pars.pdf','mse_paths.pdf', 'mse_pars.pdf', 'ranks_gtheta.pdf','ranks_gtheta_sqrt.pdf','ranks_kalpha.pdf', 'ranks.pdf', 'all_ranks.pdf']\n",
    "[bfolder.remove(bi) for bi in bfolder_ignore if bi in bfolder] # ignore specific files\n",
    "print(bfolder)\n",
    "n=len(bfolder)\n",
    "\n",
    "rhats_paths = []\n",
    "bias_mean_paths = []\n",
    "bias_mode_paths = []\n",
    "bias_median_paths = []\n",
    "\n",
    "rhats_pars = []\n",
    "bias_mean_pars = []\n",
    "bias_mode_pars = []\n",
    "bias_median_pars = []\n",
    "\n",
    "for subfolder in bfolder:\n",
    "    print(subfolder)\n",
    "    #subsubfolder = os.listdir(_folder+'/'+subfolder)\n",
    "    _subsubfolder = [x for x in os.listdir(_folder+'/'+subfolder) if bool(reg.match(x))]\n",
    "    subsubfolder = [x for x in _subsubfolder if x not in ['.DS_Store', '_ri.csv', '_ri_gtheta.csv', '_ri_gtheta_sqrt.csv', '_ri_kalpha.csv', 'other']]\n",
    "    #print(subsubfolder)\n",
    "    print(subsubfolder)\n",
    "    bfolder = subsubfolder[0]\n",
    "    #print(bfolder)\n",
    "    folder = _folder+'/'+subfolder+\"/\"+bfolder+'/'\n",
    "    print(folder)\n",
    "\n",
    "    rhats_pars.append(genfromtxt(folder+'rhats_pars.csv', delimiter=','))\n",
    "    bias_mean_pars.append(genfromtxt(folder+'bias_mean_pars.csv', delimiter=','))\n",
    "    bias_mode_pars.append(genfromtxt(folder+'bias_mode_sm_pars.csv', delimiter=','))\n",
    "    bias_median_pars.append(genfromtxt(folder+'bias_median_pars.csv', delimiter=','))\n",
    "\n",
    "    crhats = genfromtxt(folder+'rhats_paths.csv', delimiter=',')\n",
    "    if np.amax(np.array(crhats[inneridx,:]))>1.15:\n",
    "        print(\"*!!!!POSSIBLY NOT CONVERGED\")\n",
    "        print(f\"max: {np.amax(np.array(crhats))}\")\n",
    "        print(crhats)\n",
    "    rhats_paths.append(crhats)\n",
    "    #bias_mean_paths.append(genfromtxt(folder+'bias_mean.csv', delimiter=','))\n",
    "    #bias_mode_paths.append(genfromtxt(folder+'bias_mode.csv', delimiter=','))\n",
    "    #bias_median_paths.append(genfromtxt(folder+'bias_median.csv', delimiter=','))\n",
    "\n",
    "\n",
    "all_rhats_paths = np.array(rhats_paths)\n",
    "#all_bias_mean_paths = np.array(bias_mean_paths)\n",
    "#all_bias_median_paths = np.array(bias_median_paths)\n",
    "\n",
    "all_rhats_pars = np.array(rhats_pars) #data seeds x nnodes x dimensions\n",
    "all_bias_mean_pars = np.array(bias_mean_pars)\n",
    "all_bias_mode_pars = np.array(bias_mode_pars)\n",
    "all_bias_median_pars = np.array(bias_median_pars)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = re.compile('^_')\n",
    "bfolder = os.listdir(_folder)\n",
    "print(bfolder)\n",
    "#bfolder_ignore = ['.DS_Store', '_','landmarks8_ranks_root.pdf', 'rhat-paths.pdf', 'rhat-pars.pdf', 'bias_pars.pdf', 'bias_paths.pdf', 'mse_pars.pdf','mse_paths.pdf', 'ranks.pdf', 'all_ranks.pdf','sampled_parameters.pdf', 'ranks_kalpha.pdf', 'ranks_gtheta.pdf']\n",
    "[bfolder.remove(bi) for bi in bfolder_ignore if bi in bfolder] # ignore specific files\n",
    "\n",
    "_gthetas = []\n",
    "_kalphas = []\n",
    "seeds_nc = []\n",
    "for subfolder in bfolder:\n",
    "    _subsubfolder = [x for x in os.listdir(_folder+'/'+subfolder) if not bool(reg.match(x))]\n",
    "    subsubfolder = [x for x in _subsubfolder if x not in ['.DS_Store']]\n",
    "    bfolder = subsubfolder[0]\n",
    "    folder = _folder+'/'+subfolder+\"/\"+bfolder+'/'\n",
    "    cri = np.genfromtxt(folder+'true_kalpha.csv')\n",
    "    tgtheta = np.genfromtxt(folder+'true_gtheta.csv')\n",
    "    _kalphas.append(cri)\n",
    "    _gthetas.append(tgtheta)\n",
    "    seeds_nc.append(subfolder)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "all_kalphas = np.array(_kalphas)\n",
    "all_gthetas = np.array(_gthetas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(_folder+'/figures'): \n",
    "    os.mkdir(_folder+'/figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,5), sharex=True)\n",
    "\n",
    "axes[0].scatter(list(range(len(all_rhats_pars[:,0]))), all_rhats_pars[:,0])\n",
    "axes[0].hlines(y=1.1, xmin=0, xmax=len(all_rhats_pars[:,0]), color='red', linestyle='dashed', linewidth=2)\n",
    "axes[0].hlines(y=1.0, xmin=0, xmax=len(all_rhats_pars[:,0]), color='green', linestyle='dashed', linewidth=2)\n",
    "axes[0].set_title(r'$\\hat{R}$ for $\\alpha$'+f' (n={n})')\n",
    "\n",
    "axes[1].scatter(list(range(len(all_rhats_pars[:,1]))), all_rhats_pars[:,1])\n",
    "axes[1].hlines(y=1.1, xmin=0, xmax=len(all_rhats_pars[:,1]), color='red', linestyle='dashed', linewidth=2)\n",
    "axes[1].hlines(y=1.0, xmin=0, xmax=len(all_rhats_pars[:,1]), color='green', linestyle='dashed', linewidth=2)\n",
    "axes[1].set_title(r'$\\hat{R}$ for $\\sigma$'+f' (n={n})')\n",
    "plt.savefig(_folder + f'/figures/rhat-pars.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot rhat for all dimensions of all internal nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = backend_pdf.PdfPages(_folder + f'/figures/rhat-paths.pdf')\n",
    "plt.figure(1)\n",
    "max_rhat = np.amax(all_rhats_paths)\n",
    "for idx in inneridx: # loop over innernodes\n",
    "    print(idx)\n",
    "    fig, axes = plt.subplots(nrows=7, ncols=6, figsize=(25,15), sharex=True)\n",
    "    for i, ax in zip(range(all_rhats_paths.shape[2]), axes.flat): # loop over dimensions\n",
    "        ax.scatter(list(range(len(all_rhats_paths[:,idx,i]))), all_rhats_paths[:,idx,i])\n",
    "        ax.hlines(y=1.1, xmin=0, xmax=len(all_rhats_paths[:,idx,i]), color='red', linestyle='dashed', linewidth=2)\n",
    "        ax.hlines(y=1.0, xmin=0, xmax=len(all_rhats_paths[:,idx,i]), color='green', linestyle='dashed', linewidth=2)\n",
    "        ax.set_ylim(ymax=max_rhat+0.005, ymin=0.95)\n",
    "    fig.suptitle(f'Node {idx} (n={n})', size=40)\n",
    "    pdf.savefig()\n",
    "    plt.clf()\n",
    "pdf.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all combinations of parameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(all_kalphas, all_gthetas, color='green')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel(r'$\\sigma$')\n",
    "plt.title(f'Sampled parameters (n={n})')\n",
    "plt.savefig(f'{_folder}/figures/sampled_parameters.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot bias for mean, median and mode estimator (parameters)\n",
    "The code below is used to generate figure 6 in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bias_mean_pars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pars \n",
    "_bias_mean_pars =np.mean(all_bias_mean_pars, axis=0).flatten() \n",
    "_bias_median_pars =np.mean(all_bias_median_pars, axis=0).flatten() \n",
    "_bias_mode_pars =np.mean(all_bias_mode_pars, axis=0).flatten() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_true_alpha = np.mean(all_kalphas)\n",
    "mean_true_gtheta = np.mean(all_gthetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*stats.sem(all_bias_mean_pars[:,0]/mean_true_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_pars = pd.DataFrame({\n",
    "    'bias':np.array([all_bias_mean_pars.flatten(),all_bias_median_pars.flatten(), all_bias_mode_pars.flatten()]).flatten(), \n",
    "    'estimator':['mean']*2*len(all_bias_mean_pars)+['median']*2*len(all_bias_median_pars)+['mode']*2*len(all_bias_median_pars), \n",
    "    'mean_true_pars': [mean_true_alpha, mean_true_gtheta]*len(all_bias_mean_pars)+[mean_true_alpha, mean_true_gtheta]*len(all_bias_mean_pars)+[mean_true_alpha, mean_true_gtheta]*len(all_bias_mean_pars),\n",
    "    'type': ['alpha','sigma']*len(all_bias_mean_pars)+['alpha','sigma']*len(all_bias_mean_pars)+['alpha','sigma']*len(all_bias_mean_pars)})\n",
    "\n",
    "bias_pars['bias/mean'] = bias_pars.apply(lambda row: row.bias/row.mean_true_pars, axis=1)\n",
    "bias_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorbar = ('pi', 99)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize= (10,5), sharey=True)\n",
    "sns.set(style=\"ticks\", rc={\"lines.linewidth\": 0.7})\n",
    "\n",
    "sns.pointplot(data=bias_pars.loc[bias_pars['type']=='alpha'], x='estimator', \n",
    "                    y='bias/mean', linestyle='', \n",
    "                    errorbar=errorbar, marker='o',\n",
    "                    capsize=0.05, ax=ax[0])\n",
    "sns.stripplot(data=bias_pars.loc[bias_pars['type']=='alpha'], x='estimator', \n",
    "                    y='bias/mean',  \n",
    "                    color='steelblue', alpha=0.2, \n",
    "                     ax=ax[0])\n",
    "ax[0].set_title(r'$\\alpha$')\n",
    "left, right = plt.xlim()\n",
    "ax[0].hlines(0, xmin=left-0.5, xmax=right+1.5, color='black', linestyles='--')\n",
    "ax[0].xaxis.label.set_visible(False)\n",
    "#ax[0].yaxis.label.set_visible(False)\n",
    "ax[0].set(ylabel=r'$b/\\bar{\\theta}$')\n",
    "\n",
    "sns.pointplot(data=bias_pars.loc[bias_pars['type']=='sigma'], x='estimator', \n",
    "                    y='bias/mean', linestyle='', \n",
    "                    errorbar=errorbar,marker='o',\n",
    "                    color='steelblue',\n",
    "                    capsize=0.05, ax=ax[1])\n",
    "sns.stripplot(data=bias_pars.loc[bias_pars['type']=='sigma'], x='estimator', \n",
    "                    y='bias/mean',  \n",
    "                    color='steelblue', alpha=0.2,\n",
    "                     ax=ax[1])\n",
    "ax[1].set_title(r'$\\sigma$')\n",
    "ax[1].hlines(0, xmin=left-0.5, xmax=right+1.5, color='black', linestyles='--')\n",
    "ax[1].xaxis.label.set_visible(False)\n",
    "#plt.suptitle(f'Bias for parameters (n={n})')\n",
    "plt.savefig(_folder + f'/figures/bias_pars_mean_true.pdf') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = sns.boxplot(data=bias_pars, x='estimator', hue='type',\n",
    "                    y='bias/mean', linecolor=\"#137\", linewidth=.75, palette=\"Blues\")\n",
    "plt.ylabel(ylabel=r'$b/\\bar{\\theta}$')\n",
    "plt.xlabel('')\n",
    "bp.legend_.set_title(None)\n",
    "handles, legend = bp.get_legend_handles_labels()\n",
    "bp.legend(handles, [r'$\\alpha$', r'$\\sigma$'])\n",
    "plt.hlines(0, xmin=-0.5, xmax=2.5, color='black', linestyles='--')\n",
    "plt.savefig('../_BM14/paper/bias_estimators.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Wald confidence intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "def get_wald_conf(a): \n",
    "    upper = np.mean(a) - st.norm.ppf(0.995, loc=0, scale=1)*(np.std(a)/np.sqrt(len(a)))\n",
    "    lower = np.mean(a) + st.norm.ppf(0.995, loc=0, scale=1)*(np.std(a)/np.sqrt(len(a)))\n",
    "    return(np.mean(a), (upper, lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha =  bias_pars.loc[bias_pars['type']=='alpha']\n",
    "sigma =  bias_pars.loc[bias_pars['type']=='sigma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wald_conf(sigma.loc[sigma['estimator']=='mean']['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wald_conf(sigma.loc[sigma['estimator']=='median']['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wald_conf(sigma.loc[sigma['estimator']=='mode']['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wald_conf(alpha.loc[alpha['estimator']=='mean']['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wald_conf(alpha.loc[alpha['estimator']=='median']['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wald_conf(alpha.loc[alpha['estimator']=='mode']['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for generating figure XX in paper\n",
    "This is the code used for generating figure 4 in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings \n",
    "MCMC_iter = 3000\n",
    "burnin = 1000\n",
    "nthin = 1 # see from script/running conditions, not used for plotting\n",
    "folder_runs = '../_BM14/runs/44235505776566716/' #\"BM9/runs/3513656273068705/\" #\n",
    "folder_simdata = '../_BM14/simdata/44235505776566716/' #'BM9/simdata/3513656273068705/' #args.folder_simdata +'/'\n",
    "nnodes = 9\n",
    "#levelorder_tree = Tree('chazot_subtree_levelorder.nw') \n",
    "nxd = 40\n",
    "pars_name = ['kalpha', 'gtheta']\n",
    "rep_path = len(pars_name)+1\n",
    "chains = os.listdir(folder_runs) # use all chains in data seed folder \n",
    "chains = [c for c in chains if c[0] not in ['_', '.']] # remove files starting with underscore\n",
    "print(chains)\n",
    "\n",
    "# read true parameters\n",
    "true_pars = [np.genfromtxt(folder_simdata +p+\"_sim.csv\", delimiter = \",\") for p in pars_name]\n",
    "true_pars\n",
    "\n",
    "# PLOT TRACE AND DENSITY FOR PARAMETERS\n",
    "# wait with array in case of irregular dimensions \n",
    "temp_name = ['' for i in range(len(chains))]\n",
    "raw_pars = [[np.genfromtxt(folder_runs + chains[i]+'/'+temp_name[i]+par+\"s.csv\", delimiter = \",\") for i in range(len(chains))] for par in pars_name]\n",
    "raw_acceptpars = [[np.genfromtxt(folder_runs + chains[i]+'/'+temp_name[i]+\"acceptkalpha.csv\", delimiter = \",\") for i in range(len(chains))] for par in pars_name]\n",
    "\n",
    "pars = [np.array([raw_pars[j][i][burnin:MCMC_iter] for i in range(len(raw_pars[0]))]) for j in range(len(raw_pars))]\n",
    "[p.shape for p in pars]\n",
    "acceptpars = [np.array([raw_acceptpars[j][i][burnin:MCMC_iter] for i in range(len(raw_acceptpars[0]))]) for j in range(len(raw_acceptpars))]\n",
    "[ap.shape for ap in acceptpars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rhat for parameters \n",
    "parsdict = dict(zip(pars_name, pars)) \n",
    "MCMC_result = parsdict #parsdict|innernodedict\n",
    "parsres = az.convert_to_dataset(MCMC_result)\n",
    "rhat = az.rhat(parsres)\n",
    "mcse = az.mcse(parsres)\n",
    "ess = az.ess(parsres)\n",
    "az.summary(parsres)\n",
    "\n",
    "# save rhat for plotting\n",
    "rhats_par = np.array([rhat['kalpha'], rhat['gtheta']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = true_pars #[true_pars]\n",
    "keys = pars_name\n",
    "colors = sns.color_palette('pastel', len(chains))\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20,10))\n",
    "p = 0\n",
    "cp = 0\n",
    "name = ['$\\alpha$']\n",
    "for i, ax in zip(range(len(axes.flat)), axes.flat): \n",
    "        if i%2 == 0: \n",
    "            for j in range(pars[p].shape[0]): #loop over chains \n",
    "                ax.plot(pars[p][j,:], color=colors[j], alpha=0.5)\n",
    "            ax.hlines(y=true_vals[p], xmin=0, xmax=pars[p].shape[1], color='skyblue')\n",
    "            #ax.set_title(f'{keys[p]}, rhat: {round(float(np.array(rhat[keys[p]])),2)} \\n (ess: {round(float(np.array(ess[keys[p]])),2)}) ')\n",
    "            p+=1\n",
    "        if i%2==1:\n",
    "            for j in range(pars[cp].shape[0]):\n",
    "                sns.kdeplot(pars[cp][j,:], ax=ax)\n",
    "                sns.rugplot(pars[cp][j,:], ax=ax)\n",
    "            ax.axvline(x = true_vals[cp], ymin = 0, ymax = 1, color='orange') \n",
    "            #ax.set_title(f'{keys[cp]}, rhat: {round(float(np.array(rhat[keys[cp]])),2)} \\n (ess: {round(float(np.array(ess[keys[cp]])),2)}) ')#\n",
    "            cp+=1\n",
    "        #if i%3==2:\n",
    "        #    ax.scatter(list(range(len(all_rhats_pars[:,cp]))), all_rhats_pars[:,cp])\n",
    "        #    ax.hlines(y=1.1, xmin=0, xmax=len(all_rhats_pars[:,cp]), color='red', linestyle='dashed', linewidth=2)\n",
    "        #    ax.hlines(y=1.0, xmin=0, xmax=len(all_rhats_pars[:,cp]), color='green', linestyle='dashed', linewidth=2)\n",
    "        #    cp+=1\n",
    "\n",
    "#fig.suptitle(f\"Iter: {MCMC_iter}, Burnin: {burnin} \\n\", fontsize=15)\n",
    "#fig.tight_layout()\n",
    "\n",
    "axes[0,0].set_title(r'$\\alpha$ ($\\hat{R}$='+ f'{round(float(np.array(rhat[keys[0]])),2)}, ess: {round(float(np.array(ess[keys[0]])),2)})')\n",
    "axes[0,1].set_title(r'$\\alpha$ ($\\hat{R}$='+ f'{round(float(np.array(rhat[keys[0]])),2)}, ess: {round(float(np.array(ess[keys[0]])),2)})')\n",
    "#axes[0,2].set_title(r'$\\alpha$')\n",
    "\n",
    "axes[1,0].set_title(r'$\\sigma$ ($\\hat{R}$='+ f'{round(float(np.array(rhat[keys[1]])),2)}, ess: {round(float(np.array(ess[keys[1]])),2)})')\n",
    "axes[1,1].set_title(r'$\\sigma$ ($\\hat{R}$= '+ f'{round(float(np.array(rhat[keys[1]])),2)}, ess: {round(float(np.array(ess[keys[1]])),2)})')\n",
    "#axes[1,2].set_title(r'$\\sigma$')\n",
    "\n",
    "plt.savefig(f'{_folder}/figures/convergence_plot_paper.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
