{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34912b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy.stats import chi2\n",
    "from glob import glob\n",
    "\n",
    "from physhapes.plotting import *\n",
    "from physhapes.mcmc import load_mcmc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e450d5",
   "metadata": {},
   "source": [
    "# Visualize results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f730f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin_percent = 0.3\n",
    "sim_path = \"hercules_root_sigma=0.4_alpha=0.03_dt=0.05/seed=1055283113\"  # Change to your experiment path\n",
    "mcmc_path = sim_path + \"/mcmc/id=164632041\"\n",
    "results_path = mcmc_path + \"/results_*.pkl\"  # Adjust pattern as needed\n",
    "save_path = mcmc_path + \"/plots\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "chain_results = load_mcmc_results(results_path)\n",
    "param_names = [\"sigma\", \"alpha\"]  # Replace with your actual parameter names\n",
    "len(chain_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f4b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_posterior(chain_results, burnin_percent, save_path=save_path + f'/log_posterior_burnin_percent={burnin_percent}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fd731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([np.mean(result['acceptsigma']) for result in chain_results if result is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(result['acceptalpha']) for result in chain_results if result is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(result['acceptpath']) for result in chain_results if result is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beddbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_traces(chain_results, param_names, burnin_percent, savepath=save_path + f'/parameter_traces_burnin_percent={burnin_percent}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin_end = int(chain_results[0]['sigma'].shape[0] * burnin_percent)\n",
    "print(np.mean([chain_results[i]['sigma'][burnin_end:] for i in range(len(chain_results)) if chain_results[i] is not None]))\n",
    "print(np.mean([chain_results[i]['alpha'][burnin_end:] for i in range(len(chain_results)) if chain_results[i] is not None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_results[0]['settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics = compute_diagnostics(chain_results, burnin_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e1e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traces(chain_results, burnin_percent, node_idx=[0, 1, 2, 6], save_path=save_path, diagnostics=diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_from_posterior(chain_results, burnin_percent=burnin_percent, node_idx=[0, 1, 2, 6], sample_every=50, savepath=save_path, true_values=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca3c70",
   "metadata": {},
   "source": [
    "## Plot confidence ellipses from fastAnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bfc32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions \n",
    "\n",
    "def plot_confidence_ellipse(mean, cov, ax, confidence=0.95, edgecolor='red', facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Plots a confidence ellipse of a bivariate Gaussian distribution.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    mean : array-like, shape (2,)\n",
    "        The mean vector [x, y].\n",
    "    cov : array-like, shape (2, 2)\n",
    "        The 2x2 covariance matrix.\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "    confidence : float\n",
    "        Confidence level (e.g., 0.95 for 95%).\n",
    "    edgecolor : str\n",
    "        Color of the ellipse edge.\n",
    "    facecolor : str\n",
    "        Color of the ellipse face.\n",
    "    kwargs : dict\n",
    "        Additional arguments for Ellipse.\n",
    "    \"\"\"\n",
    "    # Compute the Mahalanobis distance for the given confidence level\n",
    "    chi2_val = chi2.ppf(confidence, df=2)\n",
    "    # Eigenvalues and eigenvectors\n",
    "    vals, vecs = np.linalg.eigh(cov)\n",
    "    # Sort by largest eigenvalue\n",
    "    order = vals.argsort()[::-1]\n",
    "    vals, vecs = vals[order], vecs[:, order]\n",
    "    # Angle of ellipse\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "    # Width and height (2*sqrt(eigenvalue*chi2_val))\n",
    "    width, height = 2 * np.sqrt(vals * chi2_val)\n",
    "    ellipse = Ellipse(xy=mean, width=width, height=height, angle=theta,\n",
    "                      edgecolor=edgecolor, facecolor=facecolor, lw=2, **kwargs)\n",
    "    ax.add_patch(ellipse)\n",
    "    return ellipse\n",
    "\n",
    "\n",
    "def read_fastAnc_var(directory):\n",
    "    \"\"\"\n",
    "    Read all CSV files starting with 'vars_' in the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    directory : str\n",
    "        Path to the directory containing the CSV files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with filenames as keys and pandas DataFrames as values\n",
    "    \"\"\"\n",
    "    # Find all matching files\n",
    "    pattern = os.path.join(directory, \"vars_*.csv\")\n",
    "    files = glob(pattern)\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"No files matching 'vars_*.csv' found in {directory}\")\n",
    "        return {}\n",
    "    \n",
    "    # Read each file into a dictionary\n",
    "    result = {}\n",
    "    for file_path in files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, header=0, index_col=0)\n",
    "            result[file_name] = df\n",
    "            #print(f\"Successfully loaded: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_name}: {e}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc6dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fastAnc reconstructions\n",
    "fastAnc_recon= pd.read_csv(sim_path + f\"/fastAnc/fastAnc_recon.csv\", delimiter=',', header=0, index_col=0)\n",
    "fastAnc_recon_for_plotting = pd.concat([fastAnc_recon, fastAnc_recon.iloc[:2]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read variances from fastAnc\n",
    "vars = read_fastAnc_var(sim_path+ \"/fastAnc/\")\n",
    "rows = []\n",
    "trait_names = []\n",
    "for i in range(40):\n",
    "    trait_name = f'vars_trait{i+1}.csv'\n",
    "    cvars = vars[trait_name]\n",
    "    # Flatten the DataFrame values row-wise\n",
    "    rows.append(cvars.values.flatten())\n",
    "    trait_names.append(trait_name)\n",
    "\n",
    "# Create DataFrame: rows = traits, columns = flattened (landmark, dimension, node)\n",
    "cvars_df = pd.DataFrame(rows, index=trait_names)\n",
    "\n",
    "print(cvars_df.shape)\n",
    "print(cvars_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c506db",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = 0.95  # Set your desired confidence level here\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "node_indices = [0, 1, 2, 3]  # Adjust if you have a different number of inner nodes\n",
    "\n",
    "for ax, node_idx in zip(axes.flat, node_indices):\n",
    "    #print(node_idx)\n",
    "    for landmark_id in range(0, 40, 2):\n",
    "        mean = [\n",
    "            fastAnc_recon_for_plotting.iloc[landmark_id, node_idx],\n",
    "            fastAnc_recon_for_plotting.iloc[landmark_id + 1, node_idx]\n",
    "        ]\n",
    "        cov = np.diag([\n",
    "            cvars_df.iloc[landmark_id, node_idx],\n",
    "            cvars_df.iloc[landmark_id + 1, node_idx]\n",
    "        ])\n",
    "        ax.scatter(mean[0], mean[1], s=50, color='blue')\n",
    "        plot_confidence_ellipse(mean, cov, ax, confidence=confidence_level, edgecolor='red')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Inner node {node_idx}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(sim_path + f\"/fastAnc_confidence_ellipse_all.pdf\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b190971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare posterior for plotting \n",
    "nidx = 2\n",
    "# nchain x mcmc iter x nnodes x ndim\n",
    "burnin_end = int(chain_results[0]['trees'].shape[0] * burnin_percent)\n",
    "all_posterior_samples = np.array([chain_results[i]['trees'][burnin_end:,:,:] for i in range(len(chain_results)) if chain_results[i] is not None])\n",
    "sele_node = all_posterior_samples[:,:,nidx,:].reshape(-1,all_posterior_samples.shape[3])\n",
    "print(sele_node.shape)\n",
    "\n",
    "# reshape for nicer plotting \n",
    "first_landmark = sele_node[:, :2]\n",
    "sele_node_plot = np.concatenate([sele_node, first_landmark], axis=1)\n",
    "print(sele_node_plot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8), sharex=True, sharey=True)\n",
    "xlim_min = -0.25; xlim_max = 0.35\n",
    "ylim_min = -0.25; ylim_max = 0.35\n",
    "# First subplot: fastAnc_recon with confidence intervals\n",
    "axes[0].plot(fastAnc_recon_for_plotting.iloc[0::2, nidx], fastAnc_recon_for_plotting.iloc[1::2, nidx], '--o')\n",
    "axes[0].set_xlim(xlim_min, xlim_max)\n",
    "axes[0].set_ylim(ylim_min, ylim_max)\n",
    "for i in range(0, fastAnc_recon.shape[0], 2):\n",
    "        mean = [\n",
    "            fastAnc_recon_for_plotting.iloc[i, nidx],\n",
    "            fastAnc_recon_for_plotting.iloc[i + 1, nidx]\n",
    "        ]\n",
    "        cov = np.diag([\n",
    "            cvars_df.iloc[i, nidx],\n",
    "            cvars_df.iloc[i + 1, nidx]\n",
    "        ])\n",
    "        axes[0].scatter(mean[0], mean[1], s=50, color='blue')\n",
    "        plot_confidence_ellipse(mean, cov, axes[0], confidence=confidence_level, edgecolor='red')\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=18)\n",
    "axes[0].set_title('Brownian motion confidence sets', fontsize=22)\n",
    "\n",
    "# Second subplot: sele_node_plot\n",
    "for i in range(0, sele_node_plot.shape[0], 100):\n",
    "    axes[1].plot(sele_node_plot[i,0::2], sele_node_plot[i,1::2], '--o', alpha=0.1, color='steelblue')\n",
    "axes[1].set_xlim(xlim_min, xlim_max)\n",
    "axes[1].set_ylim(ylim_min, ylim_max)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=18)\n",
    "axes[1].set_title('Posterior samples', fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(sim_path + f\"/combined_landmark_plots_ellipsis_nidx={nidx}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614346d4",
   "metadata": {},
   "source": [
    "## Plot posterior distances between the landmarks that seem to be close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6098d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Get all samples\n",
    "sele_node = all_posterior_samples[:,:,nidx,:].reshape(-1, all_posterior_samples.shape[3])\n",
    "\n",
    "# Calculate distances between landmarks 12 and 13 for each sample\n",
    "landmark12_13_distances = []\n",
    "for i in range(0, sele_node.shape[0]):\n",
    "    # Extract coordinates for landmark 12 (indices 24, 25)\n",
    "    landmark12_x = sele_node[i, 24]\n",
    "    landmark12_y = sele_node[i, 25]\n",
    "    \n",
    "    # Extract coordinates for landmark 13 (indices 26, 27)\n",
    "    landmark13_x = sele_node[i, 26]\n",
    "    landmark13_y = sele_node[i, 27]\n",
    "    \n",
    "    # Compute Euclidean distance\n",
    "    dist = np.sqrt((landmark12_x - landmark13_x)**2 + (landmark12_y - landmark13_y)**2)\n",
    "    landmark12_13_distances.append(dist)\n",
    "\n",
    "# Plot histogram of the distances\n",
    "ax.hist(landmark12_13_distances, bins=30, alpha=0.7, color='steelblue')\n",
    "ax.set_xlabel('Distance Between Landmarks 12 and 13')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Distances Between Landmarks 12 and 13')\n",
    "\n",
    "# Add statistics to the plot\n",
    "mean_dist = np.mean(landmark12_13_distances)\n",
    "median_dist = np.median(landmark12_13_distances)\n",
    "min_dist = np.min(landmark12_13_distances)\n",
    "max_dist = np.max(landmark12_13_distances)\n",
    "\n",
    "# Add vertical line at mean\n",
    "ax.axvline(x=mean_dist, color='red', linestyle='-', \n",
    "          label=f'Mean: {mean_dist:.4f}')\n",
    "\n",
    "# Add vertical line at median\n",
    "ax.axvline(x=median_dist, color='green', linestyle='--', \n",
    "          label=f'Median: {median_dist:.4f}')\n",
    "\n",
    "# Add text with statistics\n",
    "stats_text = (f\"Min: {min_dist:.4f}\\nMax: {max_dist:.4f}\\n\"\n",
    "              f\"Mean: {mean_dist:.4f}\\nMedian: {median_dist:.4f}\")\n",
    "ax.text(0.95, 0.95, stats_text, transform=ax.transAxes, \n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"/landmark12_13_distance_distribution.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Print basic statistics\n",
    "print(f\"Distance between landmarks 12 and 13:\")\n",
    "print(f\"Mean: {mean_dist:.4f}\")\n",
    "print(f\"Median: {median_dist:.4f}\")\n",
    "print(f\"Min: {min_dist:.4f}\")\n",
    "print(f\"Max: {max_dist:.4f}\")\n",
    "print(f\"Standard deviation: {np.std(landmark12_13_distances):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Get all samples\n",
    "sele_node = all_posterior_samples[:,:,nidx,:].reshape(-1, all_posterior_samples.shape[3])\n",
    "\n",
    "# Calculate distances between landmarks 12 and 13 for each sample\n",
    "landmark12_13_distances = []\n",
    "for i in range(0, sele_node.shape[0]):\n",
    "    # Extract coordinates for landmark 12 (indices 24, 25)\n",
    "    landmark12_x = sele_node[i, 0]\n",
    "    landmark12_y = sele_node[i, 1]\n",
    "    \n",
    "    # Extract coordinates for landmark 13 (indices 26, 27)\n",
    "    landmark13_x = sele_node[i, 2]\n",
    "    landmark13_y = sele_node[i, 3]\n",
    "    \n",
    "    # Compute Euclidean distance\n",
    "    dist = np.sqrt((landmark12_x - landmark13_x)**2 + (landmark12_y - landmark13_y)**2)\n",
    "    landmark12_13_distances.append(dist)\n",
    "\n",
    "# Plot histogram of the distances\n",
    "ax.hist(landmark12_13_distances, bins=30, alpha=0.7, color='steelblue')\n",
    "ax.set_xlabel('Distance Between Landmarks 0 and 1')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Distances Between Landmarks 0 and 1')\n",
    "\n",
    "# Add statistics to the plot\n",
    "mean_dist = np.mean(landmark12_13_distances)\n",
    "median_dist = np.median(landmark12_13_distances)\n",
    "min_dist = np.min(landmark12_13_distances)\n",
    "max_dist = np.max(landmark12_13_distances)\n",
    "\n",
    "# Add vertical line at mean\n",
    "ax.axvline(x=mean_dist, color='red', linestyle='-', \n",
    "          label=f'Mean: {mean_dist:.4f}')\n",
    "\n",
    "# Add vertical line at median\n",
    "ax.axvline(x=median_dist, color='green', linestyle='--', \n",
    "          label=f'Median: {median_dist:.4f}')\n",
    "\n",
    "# Add text with statistics\n",
    "stats_text = (f\"Min: {min_dist:.4f}\\nMax: {max_dist:.4f}\\n\"\n",
    "              f\"Mean: {mean_dist:.4f}\\nMedian: {median_dist:.4f}\")\n",
    "ax.text(0.95, 0.95, stats_text, transform=ax.transAxes, \n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path + \"/landmark12_13_distance_distribution.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Print basic statistics\n",
    "print(f\"Distance between landmarks 0 and 1:\")\n",
    "print(f\"Mean: {mean_dist:.4f}\")\n",
    "print(f\"Median: {median_dist:.4f}\")\n",
    "print(f\"Min: {min_dist:.4f}\")\n",
    "print(f\"Max: {max_dist:.4f}\")\n",
    "print(f\"Standard deviation: {np.std(landmark12_13_distances):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a23e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = 0.95  # Set your desired confidence level here\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "node_indices = [0, 1, 2, 3]  # Adjust if you have a different number of inner nodes\n",
    "\n",
    "for ax, node_idx in zip(axes.flat, node_indices):\n",
    "    for landmark_id in range(0, 40, 2):\n",
    "        mean = [\n",
    "            fastAnc_recon_for_plotting.iloc[landmark_id, node_idx],\n",
    "            fastAnc_recon_for_plotting.iloc[landmark_id + 1, node_idx]\n",
    "        ]\n",
    "        cov = np.diag([\n",
    "            cvars_df.iloc[landmark_id, node_idx],\n",
    "            cvars_df.iloc[landmark_id + 1, node_idx]\n",
    "        ])\n",
    "        ax.scatter(mean[0], mean[1], s=50, color='blue')\n",
    "        # Plot landmark index next to the point\n",
    "        ax.text(mean[0], mean[1], str(landmark_id // 2), fontsize=8, color='black', ha='right', va='bottom')\n",
    "        plot_confidence_ellipse(mean, cov, ax, confidence=confidence_level, edgecolor='red')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Inner node {node_idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3dea52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa27bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
