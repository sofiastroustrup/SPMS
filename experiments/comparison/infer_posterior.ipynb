{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fbd805",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f04bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import wandb\n",
    "#import argparse\n",
    "import scipy\n",
    "import pickle \n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.backends.backend_pdf as backend_pdf\n",
    "import subprocess\n",
    "import time\n",
    "import glob \n",
    "import arviz\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "#from bridge_sampling.BFFG import backward_filter, forward_guide, forward_guide_edge, get_logpsi\n",
    "#from bridge_sampling.setup_SDEs import Stratonovich_to_Ito, dtsdWsT, dWs\n",
    "#from bridge_sampling.noise_kernel import Q12\n",
    "from bridge_sampling.helper_functions import *\n",
    "\n",
    "from mcmc import *\n",
    "import subprocess\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c5fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mcmc_for_all_datasets(experiment_path, \n",
    "                              num_chains=3, \n",
    "                              num_samples=6000, \n",
    "                              dt=0.05, \n",
    "                              lambd=0.8, \n",
    "                              obs_var=0.001, \n",
    "                              rb=2, \n",
    "                              prior_sigma_min=0.0, \n",
    "                              prior_sigma_max=1.0, \n",
    "                              prior_alpha_min=0.0, \n",
    "                              prior_alpha_max=0.03, \n",
    "                              proposal_sigma_tau=0.2, \n",
    "                              proposal_alpha_tau=0.015, \n",
    "                              use_wandb=True):\n",
    "    \"\"\"Run MCMC for all datasets in the experiment path\"\"\"\n",
    "\n",
    "    \n",
    "    # Get all dataset folders\n",
    "    dataset_folders = glob.glob(f\"{experiment_path}/seed=*\")\n",
    "    \n",
    "    print(f\"Found {len(dataset_folders)} datasets in {experiment_path}\")\n",
    "    \n",
    "    # Loop through each dataset folder\n",
    "    for dataset_folder in dataset_folders:\n",
    "        # Extract the folder name\n",
    "        folder_name = os.path.basename(dataset_folder)\n",
    "        print(f\"\\nProcessing dataset: {folder_name}\")\n",
    "        \n",
    "        # Check if the required file exists\n",
    "        data_file = f\"{dataset_folder}/procrustes_aligned.csv\"\n",
    "        if not os.path.exists(data_file):\n",
    "            print(f\"  Skipping: {data_file} not found\")\n",
    "            continue\n",
    "        \n",
    "        # Generate a random seed for this batch of chains\n",
    "        seed_start = np.random.randint(0, 1000_000_000)\n",
    "        \n",
    "        # Set up output path\n",
    "        output_path = f\"{dataset_folder}/mcmc_seed={seed_start}_N={num_samples}\"\n",
    "        \n",
    "        print(f\"  Starting {num_chains} MCMC chains with seed {seed_start}\")\n",
    "        \n",
    "        # Start MCMC chains in screen sessions\n",
    "        screen_sessions = run_mcmc_in_screens(\n",
    "            num_chains=num_chains,\n",
    "            script_path=\"run_mcmc.py\",\n",
    "            seed_param=\"--seed_mcmc\",\n",
    "            seed_start=seed_start,\n",
    "            screen_prefix=f\"mcmc_{folder_name}\",  # Use unique screen names\n",
    "            script_args={\n",
    "                \"--outputpath\": output_path,\n",
    "                \"--phylopath\": \"../data/chazot_subtree_rounded.nw\",\n",
    "                \"--datapath\": data_file,\n",
    "                \"--dt\": dt,\n",
    "                \"--lambd\": lambd,\n",
    "                \"--obs_var\": obs_var,\n",
    "                \"--rb\": rb,\n",
    "                \"--N\": num_samples,\n",
    "                \"--prior_sigma_min\": prior_sigma_min,\n",
    "                \"--prior_sigma_max\": prior_sigma_max,\n",
    "                \"--prior_alpha_min\": prior_alpha_min,\n",
    "                \"--prior_alpha_max\": prior_alpha_max,\n",
    "                \"--proposal_sigma_tau\": proposal_sigma_tau,\n",
    "                \"--proposal_alpha_tau\": proposal_alpha_tau,\n",
    "                \"--use_wandb\": True\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"  Started chains for {folder_name}. Screen sessions: {', '.join(screen_sessions)}\")\n",
    "        \n",
    "        # Optional: Add a delay between datasets to avoid overloading the system\n",
    "        time.sleep(5)\n",
    "    \n",
    "    print(f\"\\nMCMC chains started for all datasets in {experiment_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7faa41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCMC settings\n",
    "num_chains = 3\n",
    "num_samples = 6000\n",
    "dt = 0.05\n",
    "lambd = 0.7\n",
    "obs_var = 0.001\n",
    "rb = 2\n",
    "prior_sigma_min = 0.0\n",
    "prior_sigma_max = 2.5\n",
    "prior_alpha_min = 0.0\n",
    "prior_alpha_max = 0.03\n",
    "proposal_sigma_tau = 0.2\n",
    "proposal_alpha_tau = 0.015\n",
    "seed_start = np.random.randint(0,1000_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e4e07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 datasets in exp_1_sigma=0.9_alpha=0.025_dt=0.05\n",
      "\n",
      "Processing dataset: seed=999303364\n",
      "  Starting 3 MCMC chains with seed 125227906\n",
      "Starting chain 1 with seed 125227906 in screen 'mcmc_seed=999303364_1'\n",
      "Starting chain 2 with seed 125227907 in screen 'mcmc_seed=999303364_2'\n",
      "Starting chain 3 with seed 125227908 in screen 'mcmc_seed=999303364_3'\n",
      "\n",
      "3 MCMC chains started in separate screen sessions.\n",
      "To attach to a screen session: screen -r <screen_name>\n",
      "To detach from a screen session: Ctrl+A, then D\n",
      "Screen sessions: mcmc_seed=999303364_1, mcmc_seed=999303364_2, mcmc_seed=999303364_3\n",
      "  Started chains for seed=999303364. Screen sessions: mcmc_seed=999303364_1, mcmc_seed=999303364_2, mcmc_seed=999303364_3\n",
      "\n",
      "MCMC chains started for all datasets in exp_1_sigma=0.9_alpha=0.025_dt=0.05\n"
     ]
    }
   ],
   "source": [
    "# Run the function\n",
    "experiment_path = \"exp_1_sigma=0.9_alpha=0.025_dt=0.05\"\n",
    "run_mcmc_for_all_datasets(experiment_path=experiment_path,\n",
    "                          num_chains=num_chains,\n",
    "                          num_samples=num_samples,\n",
    "                          dt=dt,\n",
    "                          lambd=lambd,\n",
    "                          obs_var=obs_var,\n",
    "                          rb=rb,\n",
    "                          prior_sigma_min=prior_sigma_min,\n",
    "                          prior_sigma_max=prior_sigma_max,\n",
    "                          prior_alpha_min=prior_alpha_min,\n",
    "                          prior_alpha_max=prior_alpha_max,\n",
    "                          proposal_sigma_tau=proposal_sigma_tau,\n",
    "                          proposal_alpha_tau=proposal_alpha_tau)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c900b",
   "metadata": {},
   "source": [
    "# Visualize results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef546086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import arviz as az\n",
    "import os\n",
    "import seaborn\n",
    "\n",
    "def load_mcmc_results(filepath_pattern):\n",
    "    \"\"\"\n",
    "    Load MCMC results from pickle files matching the given pattern.\n",
    "    \n",
    "    Args:\n",
    "        filepath_pattern: Pattern to match pickle files (e.g., \"results/chain_*.pkl\")\n",
    "        \n",
    "    Returns:\n",
    "        List of loaded results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for filepath in sorted(glob.glob(filepath_pattern)):\n",
    "        print(f\"Loading {filepath}\")\n",
    "        with open(filepath, 'rb') as f:\n",
    "            results.append(pickle.load(f))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85460a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diagnostics(chain_results, burnin_percent):\n",
    "    trees = np.array([chain_results[i]['trees'] for i in range(len(chain_results))])\n",
    "    trees = trees[:, int(burnin_percent*trees.shape[1]):, :, :]  # discard burnin\n",
    "    rhats = []\n",
    "    esss = []\n",
    "    for idx in range(trees.shape[2]):  # calculate for all nodes \n",
    "        innernodes = trees[:,:,idx, :]\n",
    "        keys = list(range(innernodes.shape[2]))\n",
    "        MCMCres = arviz.convert_to_dataset({k:innernodes[:,:,i] for i,k in enumerate(keys)})\n",
    "        rhats.append(arviz.rhat(MCMCres).to_array().to_numpy())\n",
    "        esss.append(arviz.ess(MCMCres).to_array().to_numpy())\n",
    "    return {'Rhat': np.array(rhats), 'ESS': np.array(esss)}\n",
    "\n",
    "\n",
    "def plot_traces(results, burnin_percent, node_idx, save_path, diagnostics=None, true_values=None): \n",
    "    colors = sns.color_palette('pastel', len(results))\n",
    "    pdf = backend_pdf.PdfPages(save_path + f'/trace_burnin_percent={burnin_percent}.pdf')\n",
    "    burnin_end = int(results[0]['trees'].shape[0] * burnin_percent)\n",
    "    plt.figure(1)\n",
    "\n",
    "    for idx in node_idx: \n",
    "        fig, axes = plt.subplots(nrows=7, ncols=6, figsize=(25,15), sharex=True)\n",
    "        fig.subplots_adjust(top=0.9)  # Adjust this value between 0 and 1\n",
    "        if true_values is not None: \n",
    "            true_innernode = true_values[idx,:]\n",
    "        for j in range(len(results)): # loop over chains\n",
    "            innernode = results[j]['trees'][:,idx, :]\n",
    "            curcol = colors[j]\n",
    "            for i, ax in zip(range(innernode.shape[1]), axes.flat): # loop over dimensions\n",
    "                ax.plot(innernode[burnin_end::,i], color = curcol, alpha=0.5)\n",
    "                if diagnostics:\n",
    "                    cur_ess = round(diagnostics['ESS'][idx][i], 2)\n",
    "                    cur_rhat = round(diagnostics['Rhat'][idx][i], 2)\n",
    "                if true_values is not None:\n",
    "                    ax.hlines(y=true_innernode[i], xmin=0, xmax=innernode.shape[0]-burnin_end, color='skyblue')\n",
    "                ax.set_title(f'{i}, Rhat={cur_rhat}, ESS: {cur_ess}')\n",
    "        fig.suptitle(f'Node {idx}', size=25)\n",
    "        pdf.savefig()\n",
    "        plt.clf()\n",
    "    pdf.close();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for plotting parameter traces\n",
    "def plot_parameter_traces(chain_results, param_names, burnin_percent):\n",
    "    \"\"\"\n",
    "    Plot the traces of MCMC parameters.\n",
    "    \n",
    "    Args:\n",
    "        chain_results: List of MCMC result dictionaries\n",
    "        param_names: List of parameter names to plot\n",
    "        burnin_percent: Percentage of samples to discard as burn-in\n",
    "    \"\"\"\n",
    "    burnin_index = int(burnin_percent * len(chain_results[0][param_names[0]]))\n",
    "    num_params = len(param_names)\n",
    "    plt.figure(figsize=(15, 5 * num_params))\n",
    "    \n",
    "    # compute convergence diagnostics\n",
    "    sigmas = [chain_results[i]['sigma'] for i in range(len(chain_results)) if chain_results[i] is not None]\n",
    "    alphas = [chain_results[i]['alpha'] for i in range(len(chain_results)) if chain_results[i] is not None]\n",
    "    MCMC_result = dict(zip([\"alpha\", \"sigma\"], [alphas, sigmas])) \n",
    "    parsres = arviz.convert_to_dataset(MCMC_result)\n",
    "    rhat = arviz.rhat(parsres)\n",
    "    ess = arviz.ess(parsres)\n",
    "    \n",
    "    for i, param in enumerate(param_names):\n",
    "        plt.subplot(num_params, 1, i + 1)\n",
    "        for j in range(len(chain_results)):\n",
    "            if chain_results[j] is not None:\n",
    "                plt.plot(chain_results[j][param][burnin_index:], label=f'Chain {j}')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel(param)\n",
    "        plt.title(f'MCMC Trace for {param} (R-hat: {rhat[param]:.2f}, ESS: {ess[param]:.1f})')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_log_posterior(result, burnin_percent): \n",
    "    \"\"\"\n",
    "    Plot the posterior distribution of the MCMC results.\n",
    "    \n",
    "    Args:\n",
    "        result: MCMC result dictionary\n",
    "        burnin_percent: Percentage of samples to discard as burn-in\n",
    "    \"\"\"\n",
    "    # Compute burn-in index\n",
    "    burnin_index = int(burnin_percent * len(result[0]['log_posterior']))\n",
    "    \n",
    "    # Plot log posterior\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    [plt.plot(result[i]['log_posterior'][burnin_index:], label=f'Chain {i}')\n",
    "     for i in range(len(result))]\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Log Posterior')\n",
    "    plt.title('MCMC Log Posterior Trace')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_samples_from_posterior(chain_results, burnin_percent, node_idx, sample_every, savepath, true_values=None):\n",
    "    pdf = backend_pdf.PdfPages(savepath + f'/samples-posterior-sample_n={sample_every}_burnin_percent={burnin_percent}.pdf')\n",
    "    \n",
    "    burnin_end = int(chain_results[0]['trees'].shape[0] * burnin_percent)\n",
    "    \n",
    "    for idx in node_idx: # loop over innernodes\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(5,5))\n",
    "        \n",
    "        # Get all samples from all chains\n",
    "        all_samples = []\n",
    "        for j in range(len(chain_results)):\n",
    "            # Make sure we have data after burnin\n",
    "            post_burnin_data = chain_results[j]['trees'][burnin_end:, idx, :]\n",
    "            #print(post_burnin_data)\n",
    "            \n",
    "            if len(post_burnin_data) > 0:\n",
    "                thinned_data = post_burnin_data[0::sample_every, :]\n",
    "                all_samples.append(thinned_data)\n",
    "        \n",
    "        # Combine all chains\n",
    "        if all_samples:\n",
    "            innernodes = np.vstack(all_samples)\n",
    "            \n",
    "            # Debug info\n",
    "            print(f\"Node {idx}: Found {len(innernodes)} samples, shape={innernodes.shape}\")\n",
    "            \n",
    "            # Close the shape by appending first landmarks\n",
    "            inode = np.append(innernodes, innernodes[:, 0:2], axis=1)\n",
    "            \n",
    "            # Plot each shape sample\n",
    "            for i in range(inode.shape[0]):\n",
    "                x_coords = inode[i, ::2]  # Every other element, starting at 0 (x coordinates)\n",
    "                y_coords = inode[i, 1::2]  # Every other element, starting at 1 (y coordinates)\n",
    "                axes.plot(x_coords, y_coords, '--.', color='steelblue', alpha=0.3)\n",
    "            \n",
    "            # Add true values if provided\n",
    "            if true_values is not None:\n",
    "                true_innernode = true_values[idx, :]\n",
    "                tinode = np.concatenate((true_innernode, true_innernode[0:2]))  \n",
    "                axes.plot(tinode[::2], tinode[1::2], '--.', color='black', linewidth=2, label='true shape')\n",
    "            \n",
    "            # Add title and format\n",
    "            fig.suptitle(f'Node {idx}', size=25)\n",
    "            fig.tight_layout()\n",
    "            axes.set_aspect('equal')  # Equal aspect ratio\n",
    "            axes.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Save the figure\n",
    "            pdf.savefig(fig)\n",
    "            \n",
    "        plt.close(fig)  # Close the figure to free memory\n",
    "    \n",
    "    pdf.close()  # Close the PDF\n",
    "    print(f\"Saved plots to {savepath}/samples-posterior-sample_n={sample_every}_burnin_percent={burnin_percent}.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_kde_contour(x, y, levels=[0.05]):\n",
    "    \n",
    "    # Create kernel density estimate\n",
    "    xy = np.vstack([x, y])\n",
    "    kde = gaussian_kde(xy)\n",
    "\n",
    "    # Create a grid to evaluate the KDE\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= 0.1 * x_range\n",
    "    x_max += 0.1 * x_range\n",
    "    y_min -= 0.1 * y_range\n",
    "    y_max += 0.1 * y_range\n",
    "    x_grid, y_grid = np.mgrid[x_min:x_max:100j, y_min:y_max:100j]\n",
    "    positions = np.vstack([x_grid.ravel(), y_grid.ravel()])\n",
    "\n",
    "    # Evaluate the KDE at the grid positions\n",
    "    z = kde(positions).reshape(x_grid.shape)\n",
    "\n",
    "    # Sort density values and find thresholds for specified levels\n",
    "    z_flat = z.flatten()\n",
    "    z_sorted = np.sort(z_flat)\n",
    "    cumsum = np.cumsum(z_sorted)\n",
    "    cumsum /= cumsum[-1]  # Normalize\n",
    "\n",
    "\n",
    "    threshold_idx = np.searchsorted(cumsum, levels)\n",
    "    threshold = z_sorted[threshold_idx]\n",
    "\n",
    "    return x_grid, y_grid, z, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f51014",
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin_percent = 0.3\n",
    "results_path = \"exp_1_sigma=0.7_alpha=0.025_dt=0.05/seed=121197884/mcmc_seed=872193302_N=5/results_*.pkl\"  # Adjust pattern as needed\n",
    "save_path = \"exp_1_sigma=0.7_alpha=0.025_dt=0.05/seed=121197884/mcmc_seed=872193302_N=5\"\n",
    "sim_path = \"exp_1_sigma=0.7_alpha=0.025_dt=0.05/seed=121197884\"\n",
    "chain_results = load_mcmc_results(results_path)\n",
    "param_names = [\"sigma\", \"alpha\"]  # Replace with your actual parameter names\n",
    "len(chain_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_posterior(chain_results, burnin_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b379d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(result['acceptsigma']) for result in chain_results if result is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(result['acceptalpha']) for result in chain_results if result is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(result['acceptpath']) for result in chain_results if result is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f922fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_traces(chain_results, param_names, burnin_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ad862",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics = compute_diagnostics(chain_results, burnin_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chain_results[0]['trees'][:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traces(chain_results, burnin_percent, node_idx=[0, 1, 2, 6], save_path=save_path, diagnostics=diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60805fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_from_posterior(chain_results, burnin_percent=0.5, node_idx=[0, 1, 2, 6], sample_every=50, savepath=save_path, true_values=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a135a2",
   "metadata": {},
   "source": [
    "## Look at posterior covariation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize landmarks with labels \n",
    "flat_true_tree = np.genfromtxt(sim_path + \"/flat_true_tree.csv\", delimiter=',')   \n",
    "plt.plot(flat_true_tree[0][0::2], flat_true_tree[0][1::2], '.', color='black', linewidth=2, label='true shape')\n",
    "n = list(range(len(flat_true_tree[0][::2])))\n",
    "for i, txt in enumerate(n):\n",
    "    plt.annotate(txt, (flat_true_tree[0][::2][i], flat_true_tree[0][1::2][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210172c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "innernode_python = [0, 1, 2, 6]\n",
    "innernode_R = [6,7,8,9]\n",
    "node = 2\n",
    "dim = [0, 2, 22]\n",
    "\n",
    "# nchain x mcmc iter x nnodes x ndim\n",
    "burnin_end = int(chain_results[0]['trees'].shape[0] * burnin_percent)\n",
    "all_posterior_samples = np.array([chain_results[i]['trees'][burnin_end:7000,:,:] for i in range(len(chain_results)) if chain_results[i] is not None])\n",
    "l0x = all_posterior_samples[:,:,node,dim[0]].flatten()\n",
    "l1x = all_posterior_samples[:,:,node,dim[1]].flatten()\n",
    "l12x = all_posterior_samples[:,:,node,dim[2]].flatten()\n",
    "\n",
    "# load confidence intervals from folder \n",
    "conf_dim0 = pd.read_csv(sim_path + f\"/fastAnc/95%_conf_trait{dim[0]+1}.csv\", header=0, index_col=0)\n",
    "conf_dim1 = pd.read_csv(sim_path + f\"/fastAnc/95%_conf_trait{dim[1]+1}.csv\", header=0, index_col=0)\n",
    "conf_dim2 = pd.read_csv(sim_path + f\"/fastAnc/95%_conf_trait{dim[2]+1}.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ea8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), sharex=True, sharey=False)\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].set_xlabel('Landmark 0 (x-coordinate)')\n",
    "axes[0].set_ylabel('Landmark 1 (x-coordinate)')\n",
    "axes[0].set_title('Brownian motion model', size=15)\n",
    "x_min, x_max = conf_dim0.iloc[0, 0], conf_dim0.iloc[0, 1]; y_min, y_max = conf_dim1.iloc[0, 0], conf_dim1.iloc[0, 1]\n",
    "padding = 0.2\n",
    "x_range = x_max - x_min\n",
    "y_range = y_max - y_min\n",
    "axes[0].set_xlim(x_min - padding * x_range, x_max + padding * x_range)\n",
    "axes[0].set_ylim(y_min - padding * y_range, y_max + padding * y_range)\n",
    "rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                         linewidth=1, \n",
    "                         edgecolor='black', \n",
    "                         facecolor='steelblue', \n",
    "                         alpha=0.5)\n",
    "axes[0].add_patch(rect)\n",
    "#axes[0].text(x_max, y_min, \"Region of interest\", \n",
    "#             fontsize=9, \n",
    "#             color='black', \n",
    "#             va='bottom')\n",
    "\n",
    "\n",
    "axes[1].set_xlabel('Landmark 0 (x-coordinate)')\n",
    "axes[1].set_ylabel('Landmark 1 (x-coordinate)')\n",
    "axes[1].set_title('Shape aware model', size=15)\n",
    "axes[1].plot(l0x, l1x, '.', color='steelblue', alpha=0.3)\n",
    "x_grid, y_grid, z, threshold = gaussian_kde_contour(l0x, l1x, levels=[0.05])\n",
    "contour = axes[1].contour(x_grid, y_grid, z, levels=[threshold], \n",
    "                         colors='red', linewidths=2)\n",
    "#axes[1].clabel(contour, inline=True, fontsize=10, fmt='%.2f')\n",
    "\n",
    "axes[2].set_xlabel('Landmark 0 (x-coordinate)')\n",
    "axes[2].set_ylabel('Landmark 12 (x-coordinate)')\n",
    "x_min, x_max = conf_dim0.iloc[0, 0], conf_dim0.iloc[0, 1]; y_min, y_max = conf_dim2.iloc[0, 0], conf_dim2.iloc[0, 1]\n",
    "axes[2].set_xlim(x_min - padding * x_range, x_max + padding * x_range)\n",
    "axes[2].set_ylim(y_min - padding * y_range, y_max + padding * y_range)\n",
    "rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                         linewidth=1, \n",
    "                         edgecolor='black', \n",
    "                         facecolor='steelblue', \n",
    "                         alpha=0.5)\n",
    "axes[2].add_patch(rect)\n",
    "\n",
    "axes[3].set_xlabel('Landmark 0 (x-coordinate)')\n",
    "axes[3].set_ylabel('Landmark 12 (x-coordinate)')\n",
    "axes[3].plot(l0x, l12x, '.', color='steelblue', alpha=0.3)\n",
    "x_grid, y_grid, z, threshold = gaussian_kde_contour(l0x, l12x, levels=[0.05])\n",
    "contour = axes[3].contour(x_grid, y_grid, z, levels=[threshold], \n",
    "                         colors='red', linewidths=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30332ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85290389",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfec8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
