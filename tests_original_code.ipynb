{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6081922",
   "metadata": {},
   "source": [
    "Notebook for double checking improvements in bridge_sampling code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48eefe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from ete3 import Tree\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tqdm import tqdm \n",
    "import argparse\n",
    "import scipy\n",
    "\n",
    "from bridge_sampling.BFFG import backward_filter, forward_guide, forward_guide_edge, get_logpsi\n",
    "from bridge_sampling.setup_SDEs import Stratonovich_to_Ito, dtsdWsT, dWs\n",
    "from bridge_sampling.noise_kernel import Q12\n",
    "from bridge_sampling.helper_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e203d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "length_root_branch = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c07da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP STOCHASTIC PROCESS\n",
    "d=2 # dimension of landmarks\n",
    "n=20 # number of landmarks\n",
    "\n",
    "# define drift and diffusion for process of interest \n",
    "b,sigma,_ = Stratonovich_to_Ito(lambda t,x,theta: jnp.zeros(n*d),\n",
    "                               lambda t,x,theta: Q12(x,theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN DATA (SETUP FOR SIMULATED DATA output structure )\n",
    "treefile = datapath+ '/'+'phylogeny.nw'\n",
    "with open(treefile, 'r') as file: \n",
    "        newick_tree = file.read()\n",
    "bphylogeny = Tree(treefile)\n",
    "\n",
    "# read data + metadata\n",
    "leaves = np.genfromtxt(datapath + '/leaves.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b1758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep tree inference tree\n",
    "bphylogeny.dist = length_root_branch # we need to add the super root branch length because it is not saved in the newick file... \n",
    "for node in bphylogeny.traverse(\"levelorder\"): \n",
    "    #node.add_feature('T', round(node.dist,1)) # this should match what is done when data is simulated\n",
    "    node.add_feature('T', node.dist) # when we simulate with simulate.py and read in the tree from simdata, then the branch lengths are already rounded\n",
    "    node.add_feature('message', None)\n",
    "    node.add_feature('theta', False)\n",
    "    if node.is_root():\n",
    "        node.add_feature('n_steps', round(node.T/dt)) \n",
    "    else: \n",
    "        node.add_feature('n_steps', round(node.T/dt)) \n",
    "\n",
    "i=0\n",
    "for leaf in bphylogeny: \n",
    "    leaf.name = i\n",
    "    leaf.add_feature('v', leaves[i])\n",
    "    leaf.add_feature('obs_var', obs_var)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44f6adf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2       0.4       0.6       0.8       1.        1.2       1.4\n",
      " 1.6       1.8000001 2.       ]\n"
     ]
    }
   ],
   "source": [
    "H_T = jnp.eye(10)*5\n",
    "F_T = jnp.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "Mdagger = jnp.linalg.inv(H_T)\n",
    "v = jnp.dot(Mdagger, F_T)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00aa359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2       0.4       0.6       0.8       1.        1.2       1.4\n",
      " 1.6       1.8000001 2.       ]\n"
     ]
    }
   ],
   "source": [
    "v = jnp.linalg.solve(H_T, F_T)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# RUN MCMC\n",
    "#### Initiate MCMC chain ####\n",
    "# initiate parameters and root \n",
    "key = jax.random.PRNGKey(seed_mcmc)\n",
    "key, *subkeys = jax.random.split(key,3)\n",
    "kalpha_cur = jax.random.uniform(subkeys[0], (1,), minval=kalpha_loc, maxval=kalpha_loc+kalpha_scale)[0]\n",
    "gtheta_cur = jax.random.uniform(subkeys[1], (1,), minval=gtheta_loc, maxval=gtheta_loc+gtheta_scale)[0]\n",
    "\n",
    "if args.super_root == 'mean':\n",
    "    print('super_root: euclidean mean')\n",
    "    super_root = np.mean(leaves, axis=0)\n",
    "elif args.super_root == 'phylomean':\n",
    "    print('super_root: phylogenetic mean')\n",
    "    #_path = datapath + '/phylogeny'\n",
    "    #print(_path)\n",
    "    #subprocess.call('Rscript get_vcv.R ' + _path, shell=True)\n",
    "    vcv = np.genfromtxt(datapath + '/phylogeny_vcv.csv', delimiter=' ')\n",
    "    super_root = 1/(np.ones(leaves.shape[0]).T@np.linalg.inv(vcv)@np.ones(leaves.shape[0]))*np.ones(leaves.shape[0]).T@np.linalg.inv(vcv)@leaves \n",
    "else:\n",
    "    print(f'super root: {args.super_root}')\n",
    "    super_root = np.genfromtxt(args.super_root, delimiter=',')\n",
    "\n",
    "print(f'Inference super root: {super_root}')\n",
    "print(f'kalpha start: {kalpha_cur}')\n",
    "print(f'gtheta start: {gtheta_cur}')\n",
    "\n",
    "np.savetxt(outputpath+'inference_root_start.csv', super_root, delimiter=\",\")\n",
    "np.savetxt(outputpath+'true_gtheta.csv', np.array([gtheta_sim]), delimiter=\",\")\n",
    "np.savetxt(outputpath+'true_kalpha.csv', np.array([kalpha_sim]), delimiter=\",\")\n",
    "\n",
    "# backwards filter\n",
    "# set theta for inference\n",
    "theta_cur = {\n",
    "    'k_alpha': kalpha_cur, # kernel amplitude\n",
    "    'inv_k_sigma': 1./(gtheta_cur)*jnp.eye(d),\n",
    "    'd':d,\n",
    "    'n':n, \n",
    "}\n",
    "\n",
    "\n",
    "# backwards filter \n",
    "data_tree_bf = backward_filter(bphylogeny, theta_cur, sigma)\n",
    "\n",
    "# get Wiener process and steps on entire tree\n",
    "key, subkey = jax.random.split(key,2) \n",
    "_dtsdWsT = dtsdWsT(bphylogeny, subkey, lambda ckey,_dts: dWs(n*d,ckey,_dts))\n",
    "\n",
    "# Initiate tree\n",
    "fge = jax.jit(lambda *x: forward_guide_edge(*x, b, sigma, theta_cur))\n",
    "initialized_tree = forward_guide(super_root, data_tree_bf,_dtsdWsT, fge) \n",
    "logpsicur = get_logpsi(initialized_tree)\n",
    "logrhotildecur = -data_tree_bf.message['c']-0.5*super_root.T@data_tree_bf.message['H'][0]@super_root+data_tree_bf.message['F'][0].T@super_root\n",
    "\n",
    "\n",
    "# results \n",
    "guided_tree = get_flat_values(initialized_tree) \n",
    "trees = np.expand_dims(guided_tree, axis=0)\n",
    "tree_counter = [1]\n",
    "\n",
    "kalphas = [kalpha_cur]\n",
    "gthetas = [gtheta_cur]\n",
    "\n",
    "\n",
    "wandb.config.update({\n",
    "    \"dt\": dt,\n",
    "    'gtheta_true': gtheta_sim,\n",
    "    \"kalpha_true\": kalpha_sim,\n",
    "    'obs_var': obs_var,\n",
    "    'proposal_sd_kalpha': proposal_sd_kalpha,\n",
    "    'proposal_sd_gtheta': proposal_sd_gtheta,\n",
    "    'kalpha uniform prior loc': kalpha_loc, \n",
    "    'kalpha uniform prior scale': kalpha_scale,\n",
    "    'gtheta uniform prior loc': gtheta_loc,\n",
    "    'gtheta uniform prior scale': gtheta_scale, \n",
    "    'cranknicholson_lambda':lambd, \n",
    "    'seed_sim_data': str(args.ds),\n",
    "    'seed_mcmc': str(seed_mcmc), \n",
    "    'k_alpha_start': kalpha_cur,\n",
    "    'gtheta_start': gtheta_cur,\n",
    "    'MCMC_iter': N, \n",
    "    'length root branch': length_root_branch,\n",
    "    'comments': f'stratonovich-ito correction = {args.sti}, inference_root_start = {args.super_root} '\n",
    "    })\n",
    "\n",
    "\n",
    "wandb.save(outputpath+'flat_true_tree.csv')\n",
    "wandb.save(outputpath+'true_gtheta.csv')\n",
    "wandb.save(outputpath+'true_kalpha.csv')\n",
    "wandb.save(outputpath+'simulated_tree.pdf')\n",
    "wandb.save(outputpath+'guided_tree.pdf')\n",
    "wandb.save(outputpath+'cur_tree.nw')\n",
    "wandb.save(outputpath+'inference_root_start.csv')\n",
    "\n",
    "acceptpath = np.zeros(N+1)\n",
    "acceptgtheta = np.zeros(N+1)\n",
    "acceptkalpha = np.zeros(N+1)\n",
    "acceptpathall = []\n",
    "\n",
    "for j in tqdm(range(N)):\n",
    "    #######################\n",
    "    ## propose path/tree ##\n",
    "    #######################\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "\n",
    "    # take a step\n",
    "    _dtsdWsTcirc = crank_nicholson_step(subkey, _dtsdWsT, lambd)\n",
    "    guidedcirc = forward_guide(super_root, data_tree_bf,_dtsdWsTcirc, fge)\n",
    "    logpsicirc = get_logpsi(guidedcirc)\n",
    "    \n",
    "    # calculate acceptance probability\n",
    "    log_r = logpsicirc - logpsicur\n",
    "    A = min(1, np.exp(log_r))\n",
    "    print(f'path acceptance probability {A}')\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    if jax.random.uniform(subkey)<A:\n",
    "        # update driving noise \n",
    "        _dtsdWsT = _dtsdWsTcirc\n",
    "\n",
    "        # update probabilities\n",
    "        logpsicur = logpsicirc\n",
    "\n",
    "        # update statistics\n",
    "        acceptpath[j+1] = 1\n",
    "        acceptpathall.append(1)\n",
    "        \n",
    "        # save new paths \n",
    "        guided_tree = get_flat_values(guidedcirc) #used to be get_flat_values_root_branch\n",
    "        trees = np.concatenate((trees, np.expand_dims(guided_tree, axis=0)), axis=0)\n",
    "        tree_counter.append(1)\n",
    "\n",
    "    else: \n",
    "        acceptpathall.append(0)\n",
    "        tree_counter[-1]+=1    \n",
    "    # log\n",
    "    inner = dict([(str(i),guided_tree[2][i]) for i in range(2)])\n",
    "    tolog = dict([('root-'+str(l),guided_tree[0][l]) for l in range(2)])\n",
    "    tolog.update(inner)\n",
    "    wandb.log(tolog)\n",
    "\n",
    "\n",
    "    #######################\n",
    "    ##   propose gtheta  ##\n",
    "    #######################\n",
    "    \n",
    "    # propose parameter, proposal is mirrored gaussian with sd\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    gthetacirc = mirrored_gaussian(subkey, gtheta_cur, proposal_sd_gtheta, 0, 10) # symmetric proposal\n",
    "    thetacirc = theta_cur.copy()\n",
    "    thetacirc['inv_k_sigma']= 1./(gthetacirc)*jnp.eye(d) # update kernel width\n",
    "\n",
    "    # do backwards filter using new parameter\n",
    "    tree_bf_circ = backward_filter(bphylogeny, thetacirc, sigma)\n",
    "    # get paths for new parameter same wiener process \n",
    "    fgecirc = jax.jit(lambda *x: forward_guide_edge(*x, b, sigma, thetacirc))\n",
    "    guidedcirc = forward_guide(super_root, tree_bf_circ,_dtsdWsT, fgecirc)  \n",
    "    logpsicirc = get_logpsi(guidedcirc)\n",
    "    logrhotildecirc = -tree_bf_circ.message['c']-0.5*super_root.T@tree_bf_circ.message['H'][0]@super_root+tree_bf_circ.message['F'][0].T@super_root\n",
    "    \n",
    "    # get acceptance probability\n",
    "    log_r = logpsicirc - logpsicur + logrhotildecirc - logrhotildecur + scipy.stats.uniform.logpdf(gthetacirc, loc=gtheta_loc, scale=gtheta_scale) - scipy.stats.uniform.logpdf(gtheta_cur, loc=gtheta_loc, scale=gtheta_scale) \n",
    "    A = min(1, np.exp(log_r))\n",
    "    print(f'gtheta acceptance probability {A}')\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    if jax.random.uniform(subkey)<A: \n",
    "        # update variables\n",
    "        gtheta_cur = gthetacirc\n",
    "        data_tree_bf = tree_bf_circ\n",
    "        theta_cur = thetacirc\n",
    "        fge = fgecirc\n",
    "\n",
    "        # update probabilities\n",
    "        logrhotildecur = logrhotildecirc \n",
    "        logpsicur = logpsicirc\n",
    "\n",
    "        # update statistics \n",
    "        acceptgtheta[j+1] = 1\n",
    "\n",
    "        # save new paths\n",
    "        guided_tree = get_flat_values(guidedcirc) #used to be get_flat_values_root_branch\n",
    "        trees = np.concatenate((trees, np.expand_dims(guided_tree, axis=0)), axis=0)\n",
    "        tree_counter.append(1)\n",
    "\n",
    "    else: \n",
    "        tree_counter[-1]+=1  \n",
    "\n",
    "    # store values \n",
    "    acceptpathall.append(0) # store in order to have path updates and innernode match\n",
    "    gthetas.append(gtheta_cur)\n",
    "    inner = dict([(str(i),guided_tree[2][i]) for i in range(2)])\n",
    "    tolog = dict([('root-'+str(l),guided_tree[0][l]) for l in range(2)])\n",
    "    tolog.update(inner)\n",
    "    tolog.update({\"gtheta\": gtheta_cur})\n",
    "    wandb.log(tolog) \n",
    "\n",
    "\n",
    "    #######################\n",
    "    ##   propose kalpha  ##\n",
    "    #######################\n",
    "    # propose parameter, proposal is mirrored gaussian with sd\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    kalphacirc = mirrored_gaussian(subkey, kalpha_cur, proposal_sd_kalpha, 0, 10) \n",
    "    thetacirc = theta_cur.copy()\n",
    "    thetacirc['k_alpha']= kalphacirc # propose rate \n",
    "\n",
    "    # do backwards filter using new parameter\n",
    "    tree_bf_circ = backward_filter(bphylogeny, thetacirc, sigma)\n",
    "    \n",
    "    # get paths for new parameter same wiener process \n",
    "    fgecirc = jax.jit(lambda *x: forward_guide_edge(*x, b, sigma, thetacirc))\n",
    "    guidedcirc = forward_guide(super_root, tree_bf_circ,_dtsdWsT, fgecirc)\n",
    "    logpsicirc = get_logpsi(guidedcirc)\n",
    "    logrhotildecirc = -tree_bf_circ.message['c']-0.5*super_root.T@tree_bf_circ.message['H'][0]@super_root+tree_bf_circ.message['F'][0].T@super_root\n",
    "    \n",
    "    # get acceptance probability\n",
    "    log_r = logpsicirc - logpsicur + logrhotildecirc - logrhotildecur + scipy.stats.uniform.logpdf(kalphacirc, loc=kalpha_loc, scale=kalpha_scale) - scipy.stats.uniform.logpdf(kalpha_cur, loc=kalpha_loc, scale=kalpha_scale) \n",
    "    A = min(1, np.exp(log_r))\n",
    "    print(f'kalpha acceptance probability {A}')\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    if jax.random.uniform(subkey)<A: \n",
    "        # update variables \n",
    "        kalpha_cur = kalphacirc\n",
    "        theta_cur = thetacirc\n",
    "        data_tree_bf = tree_bf_circ\n",
    "        fge = fgecirc\n",
    "        \n",
    "        # update probabilities\n",
    "        logrhotildecur = logrhotildecirc\n",
    "        logpsicur = logpsicirc \n",
    "\n",
    "        # update statistics\n",
    "        acceptkalpha[j+1] = 1\n",
    "\n",
    "        # save new paths\n",
    "        guided_tree = get_flat_values(guidedcirc)\n",
    "        trees = np.concatenate((trees, np.expand_dims(guided_tree, axis=0)), axis=0)\n",
    "        tree_counter.append(1)\n",
    "    else: \n",
    "        tree_counter[-1]+=1\n",
    "\n",
    "    # store values \n",
    "    acceptpathall.append(0) # store in order to have path updates and innernode match\n",
    "    kalphas.append(kalpha_cur)\n",
    "    inner = dict([(str(i),guided_tree[2][i]) for i in range(2)])\n",
    "    tolog = dict([('root-'+str(l),guided_tree[0][l]) for l in range(2)])\n",
    "    tolog.update(inner)\n",
    "    tolog.update({\"kalpha\": kalpha_cur})\n",
    "    wandb.log(tolog) \n",
    "\n",
    "    if j%20==0 or j==N-1:\n",
    "        np.savetxt(outputpath+\"kalphas.csv\", kalphas, delimiter=\",\")\n",
    "        np.savetxt(outputpath+\"acceptkalpha.csv\", acceptkalpha, delimiter=\",\")\n",
    "        np.savetxt(outputpath+\"acceptgtheta.csv\", acceptgtheta, delimiter=\",\")\n",
    "        np.savetxt(outputpath+\"acceptpath.csv\", acceptpath, delimiter=\",\") # for plotting\n",
    "        np.savetxt(outputpath+\"tree_nodes.csv\", trees.reshape(trees.shape[0],-1), delimiter=\",\") # use reshape(number of trees,59,40) to get back\n",
    "        np.savetxt(outputpath+\"tree_counter.csv\", tree_counter, delimiter=\",\")\n",
    "        np.savetxt(outputpath+\"gthetas.csv\", gthetas, delimiter=\",\")\n",
    "\n",
    "        wandb.save(outputpath+\"kalphas.csv\")\n",
    "        wandb.save(outputpath+\"gthetas.csv\")\n",
    "        wandb.save(outputpath+'acceptkalpha.csv')\n",
    "        wandb.save(outputpath+'acceptgtheta.csv')\n",
    "        wandb.save(outputpath+'acceptpath.csv')\n",
    "        wandb.save(outputpath+'tree_nodes.csv')\n",
    "        wandb.save(outputpath+'tree_counter.csv')\n",
    "    wandb.config.update({'acceptance rate path': np.mean(acceptpath[:j+1]), 'acceptance rate gtheta': np.mean(acceptgtheta[:j+1]), 'acceptance rate kalpha': np.mean(acceptkalpha[:j+1])}, allow_val_change=True)\n",
    "wandb.finish()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
